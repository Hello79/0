{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"SVM 연습문제","private_outputs":true,"provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"lYWK3uHVVqbm"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CjaYSVJyWEcc"},"source":["**2. 서포트 벡터가 무엇인가요?**"]},{"cell_type":"markdown","metadata":{"id":"q7aP2nkfXAq5"},"source":["**답** :\n"]},{"cell_type":"markdown","metadata":{"id":"l-8URMsSF5-a"},"source":["**3. SVM을 사용할 때 입력값의 스케일이 왜 중요한가요?**"]},{"cell_type":"markdown","metadata":{"id":"uW2v-wnOF8UW"},"source":["**답** :"]},{"cell_type":"markdown","metadata":{"id":"TfRaWu4dXDsf"},"source":["**8. 선형적으로 분리되는 데이터셋에 LinearSVC를 훈련시켜보세요. 그런 다음 같은 데이터셋에 SVC와 SGDClassifier를 적용해보세요. 거의 비슷한 모델이 만들어지는지 확인해보세요.**"]},{"cell_type":"code","metadata":{"id":"yj2Fd6v7XJpv"},"source":["from sklearn import datasets\n","import numpy as np\n","from sklearn.svm import LinearSVC, SVC\n","from sklearn.linear_model import SGDClassifier\n","from sklearn.preprocessing import StandardScaler\n","import matplotlib.pyplot as plt"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Fwz70i3mBV-9"},"source":["# iris data를 로드하고 x,y를 지정해줍니다.\n","#(힌트: 핸즈온 머신러닝 교재 208쪽 참고)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3_FHdGvaEE2Q"},"source":["C = 5 \n","alpha = 1 / (C * len(X))\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"aupH_y9REIv5"},"source":["# LinearSVC 학습하기\n","\n","lin_svc = LinearSVC(loss='hinge',C=C,random_state=42)\n","svc = SVC(kernel='linear',C=C)\n","sgd_clf = SGDClassifier(loss='hinge', learning_rate = 'constant', eta0=0.001, tol=1e-3,alpha=alpha,\n","                       max_iter=100000, random_state=42)\n","\n","# 위를 이용하여 데이터 스케일링 후 LinearSVC,SVC,SGDClassifier 구하기\n","\n","\n","\n","\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8tTbQTEpBWIC"},"source":["# 세 개 모델의 결정 경계를 그리기\n","# 먼저 결정 결제들의 기울기(W)와 편향(b)을 구함\n","\n","\n","\n","\n","\n","\n","\n","\n","# 결정 결계를 원본 스케일로 변환하기\n","\n","\n","\n","\n","# 세 개의 결정 경계를 모두 그리기\n","\n","\n","\n","\n","\n","# 아주 비슷한 결정 경계를 보인다. "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZNG84j53Dm6J"},"source":["# 너무 어려울 경우 https://leechamin.tistory.com/83 참고 "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"H9xWFRiYDmxo"},"source":[""],"execution_count":null,"outputs":[]}]}
