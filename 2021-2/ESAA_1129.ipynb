{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chap.7 앙상블 학습과 랜덤 포레스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import make_moons\n",
    "\n",
    "X, y = make_moons(n_samples=500, noise=0.30)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.1 투표 기반 분류기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "log_clf = LogisticRegression()\n",
    "rnd_clf = RandomForestClassifier()\n",
    "svm_clf = SVC()\n",
    "\n",
    "voting_clf = VotingClassifier(\n",
    "    estimators=[('lr', log_clf), ('rf', rnd_clf), ('svc', svm_clf)],\n",
    "    voting='hard')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('lr', LogisticRegression()),\n",
       "                             ('rf', RandomForestClassifier()), ('svc', SVC())])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voting_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression 0.84\n",
      "RandomForestClassifier 0.88\n",
      "SVC 0.896\n",
      "VotingClassifier 0.896\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "for clf in (log_clf, rnd_clf, svm_clf, voting_clf):\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(clf.__class__.__name__, accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.2 배깅과 페이스팅"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2.1 사이킷런의 배깅과 페이스팅"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "bag_clf = BaggingClassifier(\n",
    "    DecisionTreeClassifier(), n_estimators=500,\n",
    "    max_samples=100, bootstrap=True, n_jobs=-1)\n",
    "bag_clf.fit(X_train, y_train)\n",
    "y_pred = bag_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2.2 oob 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9093333333333333"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag_clf = BaggingClassifier(\n",
    "    DecisionTreeClassifier(), n_estimators=500,\n",
    "    bootstrap=True, n_jobs=-1, oob_score=True)\n",
    "bag_clf.fit(X_train, y_train)\n",
    "bag_clf.oob_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.872"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "y_pred = bag_clf.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.65425532, 0.34574468],\n",
       "       [0.98907104, 0.01092896],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.08064516, 0.91935484],\n",
       "       [0.10106383, 0.89893617],\n",
       "       [0.2311828 , 0.7688172 ],\n",
       "       [0.00568182, 0.99431818],\n",
       "       [0.        , 1.        ],\n",
       "       [0.21857923, 0.78142077],\n",
       "       [0.01041667, 0.98958333],\n",
       "       [0.        , 1.        ],\n",
       "       [0.94680851, 0.05319149],\n",
       "       [0.08717949, 0.91282051],\n",
       "       [0.0483871 , 0.9516129 ],\n",
       "       [0.57608696, 0.42391304],\n",
       "       [1.        , 0.        ],\n",
       "       [0.94535519, 0.05464481],\n",
       "       [0.        , 1.        ],\n",
       "       [0.15508021, 0.84491979],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.97142857, 0.02857143],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.88068182, 0.11931818],\n",
       "       [0.78074866, 0.21925134],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.96276596, 0.03723404],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.99421965, 0.00578035],\n",
       "       [0.8097561 , 0.1902439 ],\n",
       "       [0.18390805, 0.81609195],\n",
       "       [0.2606383 , 0.7393617 ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.90196078, 0.09803922],\n",
       "       [0.5       , 0.5       ],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.97701149, 0.02298851],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.97883598, 0.02116402],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.67272727, 0.32727273],\n",
       "       [1.        , 0.        ],\n",
       "       [0.95721925, 0.04278075],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.01010101, 0.98989899],\n",
       "       [0.85714286, 0.14285714],\n",
       "       [0.05586592, 0.94413408],\n",
       "       [0.04117647, 0.95882353],\n",
       "       [0.99029126, 0.00970874],\n",
       "       [1.        , 0.        ],\n",
       "       [0.9673913 , 0.0326087 ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.01104972, 0.98895028],\n",
       "       [0.        , 1.        ],\n",
       "       [0.15306122, 0.84693878],\n",
       "       [1.        , 0.        ],\n",
       "       [0.9673913 , 0.0326087 ],\n",
       "       [0.26804124, 0.73195876],\n",
       "       [0.29189189, 0.70810811],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.72251309, 0.27748691],\n",
       "       [0.17032967, 0.82967033],\n",
       "       [0.67336683, 0.32663317],\n",
       "       [0.05357143, 0.94642857],\n",
       "       [1.        , 0.        ],\n",
       "       [0.01058201, 0.98941799],\n",
       "       [1.        , 0.        ],\n",
       "       [0.95939086, 0.04060914],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.99456522, 0.00543478],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.24870466, 0.75129534],\n",
       "       [0.99447514, 0.00552486],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.00558659, 0.99441341],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.26775956, 0.73224044],\n",
       "       [0.05988024, 0.94011976],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.06451613, 0.93548387],\n",
       "       [0.99456522, 0.00543478],\n",
       "       [1.        , 0.        ],\n",
       "       [0.94791667, 0.05208333],\n",
       "       [0.99      , 0.01      ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.05172414, 0.94827586],\n",
       "       [0.92820513, 0.07179487],\n",
       "       [0.00497512, 0.99502488],\n",
       "       [1.        , 0.        ],\n",
       "       [0.00568182, 0.99431818],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.94652406, 0.05347594],\n",
       "       [0.01685393, 0.98314607],\n",
       "       [0.98876404, 0.01123596],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.99521531, 0.00478469],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.94416244, 0.05583756],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.32984293, 0.67015707],\n",
       "       [0.32417582, 0.67582418],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.21052632, 0.78947368],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.1734104 , 0.8265896 ],\n",
       "       [0.97619048, 0.02380952],\n",
       "       [0.        , 1.        ],\n",
       "       [0.86885246, 0.13114754],\n",
       "       [1.        , 0.        ],\n",
       "       [0.09042553, 0.90957447],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.78609626, 0.21390374],\n",
       "       [0.71568627, 0.28431373],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.4260355 , 0.5739645 ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.04519774, 0.95480226],\n",
       "       [0.        , 1.        ],\n",
       "       [0.74111675, 0.25888325],\n",
       "       [1.        , 0.        ],\n",
       "       [0.75135135, 0.24864865],\n",
       "       [0.        , 1.        ],\n",
       "       [0.99438202, 0.00561798],\n",
       "       [1.        , 0.        ],\n",
       "       [0.01176471, 0.98823529],\n",
       "       [1.        , 0.        ],\n",
       "       [0.01020408, 0.98979592],\n",
       "       [1.        , 0.        ],\n",
       "       [0.97765363, 0.02234637],\n",
       "       [0.68852459, 0.31147541],\n",
       "       [0.93193717, 0.06806283],\n",
       "       [0.64705882, 0.35294118],\n",
       "       [0.        , 1.        ],\n",
       "       [0.80412371, 0.19587629],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.16091954, 0.83908046],\n",
       "       [0.9005848 , 0.0994152 ],\n",
       "       [0.96629213, 0.03370787],\n",
       "       [0.        , 1.        ],\n",
       "       [0.9902439 , 0.0097561 ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.99456522, 0.00543478],\n",
       "       [0.08290155, 0.91709845],\n",
       "       [0.05405405, 0.94594595],\n",
       "       [0.        , 1.        ],\n",
       "       [0.06432749, 0.93567251],\n",
       "       [0.00558659, 0.99441341],\n",
       "       [0.0297619 , 0.9702381 ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.02116402, 0.97883598],\n",
       "       [1.        , 0.        ],\n",
       "       [0.92391304, 0.07608696],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.45604396, 0.54395604],\n",
       "       [0.6684492 , 0.3315508 ],\n",
       "       [0.01910828, 0.98089172],\n",
       "       [0.14689266, 0.85310734],\n",
       "       [0.86060606, 0.13939394],\n",
       "       [0.00526316, 0.99473684],\n",
       "       [0.98941799, 0.01058201],\n",
       "       [0.03921569, 0.96078431],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.06214689, 0.93785311],\n",
       "       [0.        , 1.        ],\n",
       "       [0.34343434, 0.65656566],\n",
       "       [0.        , 1.        ],\n",
       "       [0.98895028, 0.01104972],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.1849711 , 0.8150289 ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.02923977, 0.97076023],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.6961326 , 0.3038674 ],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.82524272, 0.17475728],\n",
       "       [0.9005848 , 0.0994152 ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.99484536, 0.00515464],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.1754386 , 0.8245614 ],\n",
       "       [0.24157303, 0.75842697],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.99470899, 0.00529101],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.48351648, 0.51648352],\n",
       "       [0.98159509, 0.01840491],\n",
       "       [0.01507538, 0.98492462],\n",
       "       [0.        , 1.        ],\n",
       "       [0.88095238, 0.11904762],\n",
       "       [0.23602484, 0.76397516],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.65775401, 0.34224599],\n",
       "       [0.        , 1.        ],\n",
       "       [0.039801  , 0.960199  ],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.9742268 , 0.0257732 ],\n",
       "       [0.01219512, 0.98780488],\n",
       "       [0.        , 1.        ],\n",
       "       [0.23529412, 0.76470588],\n",
       "       [0.        , 1.        ],\n",
       "       [0.09392265, 0.90607735],\n",
       "       [0.96022727, 0.03977273],\n",
       "       [0.67231638, 0.32768362],\n",
       "       [0.98412698, 0.01587302],\n",
       "       [0.20512821, 0.79487179],\n",
       "       [0.97014925, 0.02985075],\n",
       "       [0.        , 1.        ],\n",
       "       [0.26344086, 0.73655914],\n",
       "       [0.        , 1.        ],\n",
       "       [0.30857143, 0.69142857],\n",
       "       [0.26857143, 0.73142857],\n",
       "       [1.        , 0.        ],\n",
       "       [0.02617801, 0.97382199],\n",
       "       [0.17613636, 0.82386364],\n",
       "       [0.99512195, 0.00487805],\n",
       "       [0.89017341, 0.10982659],\n",
       "       [1.        , 0.        ],\n",
       "       [0.98181818, 0.01818182],\n",
       "       [0.05978261, 0.94021739],\n",
       "       [0.91111111, 0.08888889],\n",
       "       [0.99459459, 0.00540541],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.40229885, 0.59770115],\n",
       "       [0.13736264, 0.86263736],\n",
       "       [0.98550725, 0.01449275],\n",
       "       [0.17127072, 0.82872928],\n",
       "       [0.98429319, 0.01570681],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.96756757, 0.03243243],\n",
       "       [0.99418605, 0.00581395],\n",
       "       [0.00571429, 0.99428571],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.70224719, 0.29775281],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.99492386, 0.00507614],\n",
       "       [0.64640884, 0.35359116],\n",
       "       [0.06806283, 0.93193717],\n",
       "       [0.42105263, 0.57894737],\n",
       "       [0.69662921, 0.30337079],\n",
       "       [0.13513514, 0.86486486],\n",
       "       [0.87362637, 0.12637363],\n",
       "       [0.95833333, 0.04166667],\n",
       "       [1.        , 0.        ],\n",
       "       [0.19387755, 0.80612245],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.97826087, 0.02173913],\n",
       "       [0.95480226, 0.04519774],\n",
       "       [1.        , 0.        ],\n",
       "       [0.38421053, 0.61578947],\n",
       "       [0.04191617, 0.95808383],\n",
       "       [0.015625  , 0.984375  ],\n",
       "       [0.69191919, 0.30808081],\n",
       "       [0.        , 1.        ],\n",
       "       [0.92265193, 0.07734807],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.28654971, 0.71345029],\n",
       "       [0.33870968, 0.66129032],\n",
       "       [0.        , 1.        ],\n",
       "       [0.97814208, 0.02185792],\n",
       "       [0.58333333, 0.41666667],\n",
       "       [0.44324324, 0.55675676],\n",
       "       [0.9950495 , 0.0049505 ],\n",
       "       [0.0591133 , 0.9408867 ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.12021858, 0.87978142],\n",
       "       [0.98412698, 0.01587302],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.98305085, 0.01694915],\n",
       "       [1.        , 0.        ],\n",
       "       [0.0855615 , 0.9144385 ],\n",
       "       [0.00561798, 0.99438202],\n",
       "       [0.01030928, 0.98969072],\n",
       "       [0.        , 1.        ],\n",
       "       [0.53768844, 0.46231156],\n",
       "       [0.        , 1.        ],\n",
       "       [0.81151832, 0.18848168],\n",
       "       [0.05376344, 0.94623656],\n",
       "       [0.01612903, 0.98387097],\n",
       "       [0.        , 1.        ],\n",
       "       [0.11413043, 0.88586957]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag_clf.oob_decision_function_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.4 랜덤 포레스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rnd_clf = RandomForestClassifier(n_estimators=500, max_leaf_nodes=16, n_jobs=-1)\n",
    "rnd_clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred_rf = rnd_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "bag_clf = BaggingClassifier(\n",
    "    DecisionTreeClassifier(max_features=\"auto\", max_leaf_nodes=16),\n",
    "    n_estimators=500, max_samples=1.0, bootstrap=True, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.4.2 특성 중요도"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sepal length (cm) 0.09776376616199946\n",
      "sepal width (cm) 0.02175197118449179\n",
      "petal length (cm) 0.4472019998672155\n",
      "petal width (cm) 0.4332822627862932\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris()\n",
    "rnd_clf = RandomForestClassifier(n_estimators=500, n_jobs=-1)\n",
    "rnd_clf.fit(iris[\"data\"], iris[\"target\"])\n",
    "for name, score in zip(iris[\"feature_names\"], rnd_clf.feature_importances_):\n",
    "    print(name, score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.5 부스팅"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.5.1 에이다부스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=1),\n",
       "                   learning_rate=0.5, n_estimators=200)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "ada_clf = AdaBoostClassifier(\n",
    "    DecisionTreeClassifier(max_depth=1), n_estimators=200,\n",
    "    algorithm=\"SAMME.R\", learning_rate=0.5)\n",
    "ada_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.5.2 그레이디언트 부스팅"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.random.seed(42)\n",
    "X = np.random.rand(100, 1) - 0.5\n",
    "y = 3*X[:, 0]**2 + 0.05 * np.random.randn(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(max_depth=2)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "tree_reg1 = DecisionTreeRegressor(max_depth=2)\n",
    "tree_reg1.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(max_depth=2, random_state=42)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y2 = y - tree_reg1.predict(X)\n",
    "tree_reg2 = DecisionTreeRegressor(max_depth=2, random_state=42)\n",
    "tree_reg2.fit(X, y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(max_depth=2)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y3 = y2 - tree_reg2.predict(X)\n",
    "tree_reg3 = DecisionTreeRegressor(max_depth=2)\n",
    "tree_reg3.fit(X, y3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.75026781])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_new = np.array([[0.8]])\n",
    "y_pred = sum(tree.predict(X_new) for tree in (tree_reg1, tree_reg2, tree_reg3))\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(learning_rate=1.0, max_depth=2, n_estimators=3)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "gbrt = GradientBoostingRegressor(max_depth=2, n_estimators=3, learning_rate=1.0)\n",
    "gbrt.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(max_depth=2, n_estimators=85)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y)\n",
    "\n",
    "gbrt = GradientBoostingRegressor(max_depth=2, n_estimators=120)\n",
    "gbrt.fit(X_train, y_train)\n",
    "\n",
    "errors = [mean_squared_error(y_val, y_pred)\n",
    "          for y_pred in gbrt.staged_predict(X_val)]\n",
    "bst_n_estimators = np.argmin(errors) + 1\n",
    "\n",
    "gbrt_best = GradientBoostingRegressor(max_depth=2, n_estimators=bst_n_estimators)\n",
    "gbrt_best.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbrt = GradientBoostingRegressor(max_depth=2, warm_start=True)\n",
    "\n",
    "min_val_error = float(\"inf\")\n",
    "error_going_up = 0\n",
    "for n_estimators in range(1, 120):\n",
    "    gbrt.n_estimators = n_estimators\n",
    "    gbrt.fit(X_train, y_train)\n",
    "    y_pred = gbrt.predict(X_val)\n",
    "    val_error = mean_squared_error(y_val, y_pred)\n",
    "    if val_error < min_val_error:\n",
    "        min_val_error = val_error\n",
    "        error_going_up = 0\n",
    "    else:\n",
    "        error_going_up += 1\n",
    "        if error_going_up == 5:\n",
    "            break  # 조기 종료"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation MSE: 0.003684854933316534\n"
     ]
    }
   ],
   "source": [
    "import xgboost\n",
    "\n",
    "xgb_reg = xgboost.XGBRegressor()\n",
    "xgb_reg.fit(X_train, y_train)\n",
    "y_pred = xgb_reg.predict(X_val)\n",
    "\n",
    "val_error = mean_squared_error(y_val, y_pred) \n",
    "print(\"Validation MSE:\", val_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-rmse:0.22055\n",
      "[1]\tvalidation_0-rmse:0.16547\n",
      "[2]\tvalidation_0-rmse:0.12243\n",
      "[3]\tvalidation_0-rmse:0.10044\n",
      "[4]\tvalidation_0-rmse:0.08467\n",
      "[5]\tvalidation_0-rmse:0.07344\n",
      "[6]\tvalidation_0-rmse:0.06728\n",
      "[7]\tvalidation_0-rmse:0.06383\n",
      "[8]\tvalidation_0-rmse:0.06125\n",
      "[9]\tvalidation_0-rmse:0.05959\n",
      "[10]\tvalidation_0-rmse:0.05902\n",
      "[11]\tvalidation_0-rmse:0.05852\n",
      "[12]\tvalidation_0-rmse:0.05844\n",
      "[13]\tvalidation_0-rmse:0.05801\n",
      "[14]\tvalidation_0-rmse:0.05747\n",
      "[15]\tvalidation_0-rmse:0.05772\n",
      "[16]\tvalidation_0-rmse:0.05778\n",
      "Validation MSE: 0.0033024085351185672\n"
     ]
    }
   ],
   "source": [
    "xgb_reg.fit(X_train, y_train,\n",
    "                eval_set=[(X_val, y_val)], early_stopping_rounds=2)\n",
    "y_pred = xgb_reg.predict(X_val)\n",
    "\n",
    "val_error = mean_squared_error(y_val, y_pred) \n",
    "print(\"Validation MSE:\", val_error)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
